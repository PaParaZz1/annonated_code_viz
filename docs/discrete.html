<!DOCTYPE html>
<html><head><meta charset="utf-8"></meta><title>Annonated Algorithm Visualization</title><link rel="stylesheet" href="pylit.css?v=1"></link><link rel="stylesheet" href="solarized.css"></link><link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/katex@0.16.3/dist/katex.min.css" integrity="sha384-Juol1FqnotbkyZUT5Z7gUPjQ9gzlwCENvUZTpQBAPxtusdwFLRy382PSDx5UUJ4/" crossorigin="anonymous"></link><script src="https://cdn.jsdelivr.net/npm/katex@0.16.3/dist/katex.min.js" integrity="sha384-97gW6UIJxnlKemYavrqDHSX3SiygeOwIZhwyOKRfSaf0JWKRVj9hLASHgFTzT+0O" crossorigin="anonymous"></script><script src="https://cdn.jsdelivr.net/npm/katex@0.16.3/dist/contrib/auto-render.min.js" integrity="sha384-+VBxd3r6XgURycqtZ117nYw44OOcIax56Z4dCRWbxyPt0Koah1uHoK0o4+/RRE05" crossorigin="anonymous" onload="renderMathInElement(document.body);" defer="True"></script><link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/codemirror@5.61.0/lib/codemirror.min.css"></link><script src="https://cdn.jsdelivr.net/npm/codemirror@5.61.0/lib/codemirror.min.js"></script><script src="https://cdn.jsdelivr.net/npm/codemirror@5.61.0/mode/python/python.min.js"></script></head><body><div class="section" id="section-0"><div class="docs doc-strings"><p><b>PyTorch implementation of "sampling discrete action" in PPO</b></p><a href="https://github.com/opendilab/PPOxFamily" target="_blank"><img alt="GitHub" style="max-width:100%;" src="https://img.shields.io/github/stars/opendilab/PPOxFamily?style=social"></img></a>  <a href="https://space.bilibili.com/1112854351?spm_id_from=333.337.0.0" target="_blank"><img alt="bilibili" style="max-width:100%;" src="https://img.shields.io/badge/bilibili-video%20course-blue"></img></a>  <a href="https://twitter.com/OpenDILab" rel="nofollow" target="_blank"><img alt="twitter" style="max-width:100%;" src="https://img.shields.io/twitter/follow/opendilab?style=social"></img></a><br><a href="https://github.com/opendilab/PPOxFamily" target="_blank">View code on GitHub</a></div></div><div class="section" id="section-1"><div class="docs doc-strings"><p>    <b>Overview</b><br>        The function of sampling discrete action, input shape = (B, action_shape), output shape = (B, ).<br>        In this example, batch_shape = (B, ), event_shape = (), sample_shape = ().</p></div><div class="code"><pre><code id="code_1" name="py_code">import torch
import torch.nn as nn


def sample_action(logits: torch.Tensor) -> torch.Tensor:</code></pre></div></div><div class="section" id="section-3"><div class="docs doc-strings"><p>    Transform logit (raw output of policy network, e.g. last fully connected layer) into probability.</p></div><div class="code"><pre><code id="code_3" name="py_code">    probs = torch.softmax(logits, dim=-1)</code></pre></div></div><div class="section" id="section-4"><div class="docs doc-strings"><p>    Construct categorical distribution.<br>    link: https://en.wikipedia.org/wiki/Categorical_distribution</p></div><div class="code"><pre><code id="code_4" name="py_code">    dist = torch.distributions.Categorical(probs=probs)</code></pre></div></div><div class="section" id="section-5"><div class="docs doc-strings"><p>    Sample one discrete action per sample and return it.</p></div><div class="code"><pre><code id="code_5" name="py_code">    return dist.sample()

</code></pre></div></div><div class="section" id="section-6"><div class="docs doc-strings"><p>    <b>Overview</b><br>        The function of testing sampling discrete action. Construct a naive policy and sample a group of action.</p></div><div class="code"><pre><code id="code_6" name="py_code">def test_sample_action():</code></pre></div></div><div class="section" id="section-8"><div class="docs doc-strings"><p>    Set batch_size = 4, obs_shape = 10, action_shape = 6.</p></div><div class="code"><pre><code id="code_8" name="py_code">    B, obs_shape, action_shape = 4, 10, 6</code></pre></div></div><div class="section" id="section-9"><div class="docs doc-strings"><p>    Generate state data from uniform distribution.</p></div><div class="code"><pre><code id="code_9" name="py_code">    state = torch.rand(B, obs_shape)</code></pre></div></div><div class="section" id="section-10"><div class="docs doc-strings"><p>    Define policy network, we use a two-layer MLP for example.</p></div><div class="code"><pre><code id="code_10" name="py_code">    policy_network = nn.Sequential(
        nn.Linear(10, 16),
        nn.ReLU(),
        nn.Linear(16, action_shape)
    )</code></pre></div></div><div class="section" id="section-11"><div class="docs doc-strings"><p>    Policy network forward procedure, input state and output logits.</p></div><div class="code"><pre><code id="code_11" name="py_code">    logits = policy_network(state)
    assert logits.shape == (B, action_shape)</code></pre></div></div><div class="section" id="section-12"><div class="docs doc-strings"><p>    Sample action accoding to corresponding logits.</p></div><div class="code"><pre><code id="code_12" name="py_code">    action = sample_action(logits)
    assert action.shape == (B, )

</code></pre></div></div></body><script type="text/javascript">
window.onload = function(){
    var codeElement = document.getElementsByName('py_code');
    var lineCount = 1;
    for (var i = 0; i < codeElement.length; i++) {
        var code = codeElement[i].innerText;
        if (code.length <= 1) {
            continue;
        }

        codeElement[i].innerHTML = "";

        var codeMirror = CodeMirror(
          codeElement[i],
          {
            value: code,
            mode: "python",
            theme: "solarized dark",
            lineNumbers: true,
            firstLineNumber: lineCount,
            readOnly: true,
            lineWrapping: true,
          }
        );
        var noNewLineCode = code.replace(/[\r\n]/g, "");
        lineCount += code.length - noNewLineCode.length + 1;
    }
};
</script></html>